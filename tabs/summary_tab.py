"""
AIè¦ç´„ã‚¿ãƒ–ã®è¡¨ç¤ºå‡¦ç†
"""

import datetime
import streamlit as st
import pandas as pd
from elasticsearch import Elasticsearch
from config import get_secret
from data_fetcher import fetch_search_results
from openai_helper import get_openai_client, generate_summary
from prompt import get_summary_prompt, get_custom_prompt


def render_summary_tab(
    es: Elasticsearch,
    query: dict,
    jichitai: pd.DataFrame,
    catmap: pd.DataFrame,
    result_limit: int
):
    """
    AIè¦ç´„ã‚¿ãƒ–ã®è¡¨ç¤º
    
    Args:
        es: Elasticsearchã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        query: æ¤œç´¢ã‚¯ã‚¨ãƒª
        jichitai: è‡ªæ²»ä½“ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿
        catmap: ã‚«ãƒ†ã‚´ãƒªãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿
        result_limit: è¡¨ç¤ºä»¶æ•°ä¸Šé™
    """
    st.subheader("ğŸ¤– GPT ã«ã‚ˆã‚‹è¦ç´„")
    
    # APIã‚­ãƒ¼ã®ç¢ºèª
    openai_api_key = get_secret("OPENAI_API_KEY")
    if not openai_api_key:
        st.error("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Streamlit Secretsã« `OPENAI_API_KEY` ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
        return
    
    # æ¤œç´¢çµæœã®ç¢ºèª
    if not query:
        st.warning("ã¾ãšæ¤œç´¢æ¡ä»¶ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return
    
    df_results = fetch_search_results(es, query, jichitai, catmap, result_limit)
    
    if df_results.empty:
        st.warning("è¦ç´„ã™ã‚‹æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ¤œç´¢æ¡ä»¶ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return
    
    st.info(f"ğŸ“Š æ¤œç´¢çµæœ: {len(df_results)}ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    model_options = {
        "GPT-4o": "gpt-4o",
        "GPT-4o mini": "gpt-4o-mini",
        "GPT-4 Turbo": "gpt-4-turbo-preview",
        "GPT-3.5 Turbo": "gpt-3.5-turbo"
    }
    
    selected_model_name = st.selectbox(
        "ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«",
        options=list(model_options.keys()),
        index=0,
        help="GPT-4oãŒæœ€æ–°ã§é«˜æ€§èƒ½ã§ã™ã€‚ã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆãŸã„å ´åˆã¯GPT-4o miniã¾ãŸã¯GPT-3.5 Turboã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"
    )
    selected_model = model_options[selected_model_name]
    
    # è¦ç´„ãƒ¢ãƒ¼ãƒ‰é¸æŠ
    summary_mode = st.radio(
        "è¦ç´„ãƒ¢ãƒ¼ãƒ‰",
        ["è‡ªå‹•è¦ç´„", "ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"],
        horizontal=True
    )
    
    # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å…¥åŠ›
    custom_instruction = ""
    if summary_mode == "ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ":
        custom_instruction = st.text_area(
            "AIã¸ã®æŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            placeholder="ä¾‹: ã“ã‚Œã‚‰ã®æ–‡æ›¸ã‹ã‚‰ç’°å¢ƒæ”¿ç­–ã«é–¢ã™ã‚‹å…±é€šã®èª²é¡Œã‚’3ã¤æŠ½å‡ºã—ã¦ãã ã•ã„",
            height=100
        )
    
    # è¦ç´„å®Ÿè¡Œãƒœã‚¿ãƒ³
    if st.button("ğŸš€ è¦ç´„ã‚’å®Ÿè¡Œ", type="primary"):
        with st.spinner("AIãŒè¦ç´„ã‚’ç”Ÿæˆä¸­..."):
            try:
                # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
                client = get_openai_client(openai_api_key)
                
                # DataFrameã‚’è¾æ›¸ã®ãƒªã‚¹ãƒˆã«å¤‰æ›
                documents = df_results.to_dict('records')
                
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
                if summary_mode == "è‡ªå‹•è¦ç´„":
                    prompt = get_summary_prompt(documents)
                else:
                    if not custom_instruction:
                        st.error("ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                        st.stop()
                    prompt = get_custom_prompt(documents, custom_instruction)
                
                # è¦ç´„ç”Ÿæˆ
                summary = generate_summary(client, prompt, model=selected_model)
                
                if summary:
                    st.success("âœ… è¦ç´„ãŒå®Œæˆã—ã¾ã—ãŸ")
                    
                    # è¦ç´„çµæœã®è¡¨ç¤º
                    st.markdown("### ğŸ“ è¦ç´„çµæœ")
                    st.markdown(summary)
                    
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                    st.download_button(
                        label="ğŸ“¥ è¦ç´„ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=summary,
                        file_name=f"summary_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain"
                    )
                else:
                    st.error("è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    # ä½¿ç”¨ä¸Šã®æ³¨æ„
    with st.expander("â„¹ï¸ AIè¦ç´„ã®ä½¿ç”¨ä¸Šã®æ³¨æ„"):
        st.markdown("""
        - AIã«ã‚ˆã‚‹è¦ç´„ã¯å‚è€ƒæƒ…å ±ã§ã™ã€‚é‡è¦ãªæ±ºå®šã«ã¯å¿…ãšåŸæ–‡ã‚’ç¢ºèªã—ã¦ãã ã•ã„
        - æ¤œç´¢çµæœãŒå¤šã„å ´åˆã€å‡¦ç†ã«æ™‚é–“ãŒã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™
        - æœ¬æ–‡ã¯æœ€å¤§2000æ–‡å­—ã¾ã§ä½¿ç”¨ã•ã‚Œã¾ã™
        - OpenAI APIã®åˆ©ç”¨åˆ¶é™ã«å¿œã˜ã¦ã€ä¸€åº¦ã«å‡¦ç†ã§ãã‚‹ä»¶æ•°ã«åˆ¶é™ãŒã‚ã‚Šã¾ã™
        - ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ã‚³ã‚¹ãƒˆãŒç•°ãªã‚Šã¾ã™ï¼š
          - **GPT-4o**: æœ€æ–°ã§é«˜æ€§èƒ½ï¼ˆã‚„ã‚„é«˜ã‚³ã‚¹ãƒˆï¼‰
          - **GPT-4o mini**: GPT-4oã®è»½é‡ç‰ˆï¼ˆãƒãƒ©ãƒ³ã‚¹å‹ï¼‰
          - **GPT-4 Turbo**: é«˜æ€§èƒ½ï¼ˆé«˜ã‚³ã‚¹ãƒˆï¼‰
          - **GPT-3.5 Turbo**: é«˜é€Ÿã§ä½ã‚³ã‚¹ãƒˆ
        """)