"""
AIè¦ç´„ã‚¿ãƒ–ã®è¡¨ç¤ºå‡¦ç†ï¼ˆãƒãƒƒãƒå‡¦ç†+ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œç‰ˆãƒ»ã‚¨ãƒ©ãƒ¼ä¿®æ­£ç‰ˆï¼‰
"""

import datetime
import time
import streamlit as st
import pandas as pd
from elasticsearch import Elasticsearch
from config import get_secret
from data_fetcher import fetch_search_results
from openai_helper import get_openai_client, generate_summary, get_user_openai_api_key
from prompt import get_summary_prompt, get_custom_prompt, get_custom_batch_prompt, get_custom_integration_prompt


# ===== å®šæ•°å®šç¾© =====
MAX_DOCS_FOR_SUMMARY = 1000  # æœ€å¤§æ–‡æ›¸æ•°
BATCH_SIZE = 100  # 1ãƒãƒƒãƒã‚ãŸã‚Šã®æ–‡æ›¸æ•°
MAX_CHARS_PER_DOC = 800  # æœ¬æ–‡ã®æœ€å¤§æ–‡å­—æ•°


def render_summary_tab(
    es: Elasticsearch,
    query: dict,
    jichitai: pd.DataFrame,
    catmap: pd.DataFrame,
    result_limit: int
):
    """
    AIè¦ç´„ã‚¿ãƒ–ã®è¡¨ç¤ºï¼ˆãƒãƒƒãƒå‡¦ç†+ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œï¼‰
    
    Args:
        es: Elasticsearchã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        query: æ¤œç´¢ã‚¯ã‚¨ãƒª
        jichitai: è‡ªæ²»ä½“ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿
        catmap: ã‚«ãƒ†ã‚´ãƒªãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿
        result_limit: è¡¨ç¤ºä»¶æ•°ä¸Šé™
    """
    st.subheader("ğŸ¤– GPT ã«ã‚ˆã‚‹è¦ç´„")
    
    # APIã‚­ãƒ¼ã®ç¢ºèªï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å€‹åˆ¥â†’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å„ªå…ˆé †ä½ï¼‰
    openai_api_key = get_user_openai_api_key()
    if not openai_api_key:
        st.error("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç†è€…ã«å•ã„åˆã‚ã›ã‚‹ã‹ã€Streamlit Secretsã« `OPENAI_API_KEY` ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
        return
    
    # æ¤œç´¢çµæœã®ç¢ºèª
    if not query:
        st.warning("ã¾ãšæ¤œç´¢æ¡ä»¶ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return
    
    df_results = fetch_search_results(es, query, jichitai, catmap, result_limit)
    
    if df_results.empty:
        st.warning("è¦ç´„ã™ã‚‹æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ¤œç´¢æ¡ä»¶ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return
    
    total_docs = len(df_results)
    if total_docs > MAX_DOCS_FOR_SUMMARY:
        st.error(f"âš ï¸ æ¤œç´¢çµæœãŒ{total_docs}ä»¶ã‚ã‚Šã¾ã™ã€‚åˆ†æå¯¾è±¡ã¯ä¸Šé™{MAX_DOCS_FOR_SUMMARY}ä»¶ã¾ã§ã§ã™ã€‚æ¤œç´¢æ¡ä»¶ã‚’çµã‚Šè¾¼ã‚“ã§ãã ã•ã„ã€‚")
        return
    
    st.info(f"ğŸ“Š è¦ç´„å¯¾è±¡: {total_docs}ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    model_options = {
        "GPT-4o mini": "gpt-4o-mini",
    }
    
    selected_model_name = st.selectbox(
        "ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«",
        options=list(model_options.keys()),
        index=0,
        help="GPT-4o miniã§æ¤œè¨¼ä¸­ã§ã™ã€‚"
    )
    selected_model = model_options[selected_model_name]
    
    # è¦ç´„ãƒ¢ãƒ¼ãƒ‰é¸æŠ
    summary_mode = st.radio(
        "è¦ç´„ãƒ¢ãƒ¼ãƒ‰",
        ["è‡ªå‹•è¦ç´„", "ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"],
        horizontal=True
    )
    
    # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å…¥åŠ›
    custom_instruction = ""
    if summary_mode == "ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ":
        custom_instruction = st.text_area(
            "AIã¸ã®æŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            placeholder="ä¾‹: ã“ã‚Œã‚‰ã®æ–‡æ›¸ã‹ã‚‰ç’°å¢ƒæ”¿ç­–ã«é–¢ã™ã‚‹å…±é€šã®èª²é¡Œã‚’3ã¤æŠ½å‡ºã—ã¦ãã ã•ã„",
            height=100
        )
    
    # ===== ãƒãƒƒãƒå‡¦ç†ã®æ¨å®šå€¤è¨ˆç®— =====
    total_batches = (total_docs + BATCH_SIZE - 1) // BATCH_SIZE  # åˆ‡ã‚Šä¸Šã’
    
    # æ¨å®šå€¤ã®è¨ˆç®—
    estimated_time_per_batch = 60  # ç§’
    estimated_total_time = total_batches * estimated_time_per_batch
    estimated_cost_per_batch = 0.10  # ãƒ‰ãƒ«
    estimated_total_cost = total_batches * estimated_cost_per_batch
    
    # å®Ÿè¡Œå‰ã®ç¢ºèªç”»é¢
    if summary_mode == "ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ" and custom_instruction:
        with st.expander("âš ï¸ å®Ÿè¡Œå†…å®¹ã®ç¢ºèª", expanded=True):
            st.markdown(f"""
            **ã‚ãªãŸã®æŒ‡ç¤º:**  
            {custom_instruction}
            
            **ğŸ“Š å‡¦ç†å†…å®¹:**
            - å¯¾è±¡æ–‡æ›¸æ•°: {total_docs}ä»¶
            - ãƒãƒƒãƒæ•°: {total_batches}ãƒãƒƒãƒï¼ˆ{BATCH_SIZE}ä»¶ãšã¤ï¼‰
            - æ¨å®šå‡¦ç†æ™‚é–“: ç´„{estimated_total_time // 60}-{estimated_total_time // 60 + 3}åˆ†
            - æ¨å®šã‚³ã‚¹ãƒˆ: ç´„${estimated_total_cost:.2f}-${estimated_total_cost * 1.5:.2f}
            
            **ğŸ“ å‡¦ç†ã®æµã‚Œ:**
            1. å„ãƒãƒƒãƒã§æŒ‡ç¤ºã‚’å®Ÿè¡Œï¼ˆ{total_batches}å›ï¼‰
            2. å…¨ãƒãƒƒãƒã®çµæœã‚’çµ±åˆï¼ˆ1å›ï¼‰
            3. æœ€çµ‚çµæœã‚’è¡¨ç¤º
            
            **â„¹ï¸ æ³¨æ„:**  
            ãƒãƒƒãƒã”ã¨ã®åˆ†æã®ãŸã‚ã€ã€Œæœ€ã‚‚ã€œã€ã€ŒTOP3ã€ãªã©ã®æŒ‡ç¤ºã¯æœ€çµ‚çµ±åˆæ™‚ã«é©ç”¨ã•ã‚Œã¾ã™
            """)
    
    # è¦ç´„å®Ÿè¡Œãƒœã‚¿ãƒ³
    if st.button("ğŸš€ è¦ç´„ã‚’å®Ÿè¡Œ", type="primary", key="execute_summary_button"):
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ¢ãƒ¼ãƒ‰ã§æŒ‡ç¤ºãŒæœªå…¥åŠ›ã®å ´åˆ
        if summary_mode == "ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ" and not custom_instruction:
            st.error("ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        
        # ä¸­æ–­ãƒ•ãƒ©ã‚°ã®åˆæœŸåŒ–
        if "stop_processing" not in st.session_state:
            st.session_state.stop_processing = False
        
        try:
            # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
            client = get_openai_client(openai_api_key)
            
            # ===== å¿…è¦ãªåˆ—ã ã‘ã‚’æŠ½å‡º =====
            essential_columns = [
                'éƒ½é“åºœçœŒ', 
                'å¸‚åŒºç”ºæ‘', 
                'è³‡æ–™ã‚«ãƒ†ã‚´ãƒª', 
                'è³‡æ–™å', 
                'æœ¬æ–‡', 
                'é–‹å§‹å¹´åº¦', 
                'çµ‚äº†å¹´åº¦'
            ]
            
            available_columns = [col for col in essential_columns if col in df_results.columns]
            df_essential = df_results[available_columns].copy()
            
            # ===== ãƒ‡ãƒ¼ã‚¿ã‚’ã‚½ãƒ¼ãƒˆï¼ˆã¾ã¨ã¾ã‚Šã®ã‚ã‚‹åˆ†æã®ãŸã‚ï¼‰ =====
            sort_columns = []
            if 'å›£ä½“ã‚³ãƒ¼ãƒ‰' in df_results.columns:
                df_essential['å›£ä½“ã‚³ãƒ¼ãƒ‰'] = df_results['å›£ä½“ã‚³ãƒ¼ãƒ‰']
                sort_columns.append('å›£ä½“ã‚³ãƒ¼ãƒ‰')
            if 'é–‹å§‹å¹´åº¦' in df_essential.columns:
                sort_columns.append('é–‹å§‹å¹´åº¦')
            if 'ãƒ•ã‚¡ã‚¤ãƒ«ID' in df_results.columns:
                df_essential['ãƒ•ã‚¡ã‚¤ãƒ«ID'] = df_results['ãƒ•ã‚¡ã‚¤ãƒ«ID']
                sort_columns.append('ãƒ•ã‚¡ã‚¤ãƒ«ID')
            
            if sort_columns:
                df_essential = df_essential.sort_values(by=sort_columns).reset_index(drop=True)
            
            # æœ¬æ–‡ã‚’æŒ‡å®šæ–‡å­—æ•°ã«åˆ¶é™
            if 'æœ¬æ–‡' in df_essential.columns:
                df_essential['æœ¬æ–‡'] = df_essential['æœ¬æ–‡'].apply(
                    lambda x: str(x)[:MAX_CHARS_PER_DOC] if pd.notna(x) else ""
                )
            
            # DataFrameã‚’è¾æ›¸ã®ãƒªã‚¹ãƒˆã«å¤‰æ›
            all_documents = df_essential.to_dict('records')
            
            # ===== ãƒãƒƒãƒå‡¦ç†ã®å®Ÿè¡Œ =====
            batch_results = []
            processing_times = []
            
            # é€²æ—è¡¨ç¤ºç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
            progress_placeholder = st.empty()
            result_placeholder = st.empty()
            
            # ãƒãƒƒãƒå‡¦ç†ã®é€²æ—è¡¨ç¤º
            with progress_placeholder.container():
                st.markdown(f"### ğŸ”„ {'ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ' if summary_mode == 'ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ' else 'è‡ªå‹•è¦ç´„'}ã‚’å®Ÿè¡Œä¸­...")
                
                if summary_mode == "ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ":
                    st.info(f"**ã‚ãªãŸã®æŒ‡ç¤º:** {custom_instruction}")
                
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # ä¸­æ–­ãƒœã‚¿ãƒ³ï¼ˆä¸€æ„ã®ã‚­ãƒ¼ã‚’ä½¿ç”¨ï¼‰
                stop_col1, stop_col2 = st.columns([1, 5])
                with stop_col1:
                    stop_button = st.button("â¹ï¸ ä¸­æ–­", key=f"stop_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f')}")
                if stop_button:
                    st.session_state.stop_processing = True
            
            # å„ãƒãƒƒãƒã‚’å‡¦ç†
            for batch_idx in range(total_batches):
                # ä¸­æ–­ãƒã‚§ãƒƒã‚¯
                if st.session_state.get("stop_processing", False):
                    progress_placeholder.empty()
                    with result_placeholder.container():
                        st.warning("âš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
                    st.session_state.stop_processing = False
                    break
                
                # ãƒãƒƒãƒã®ç¯„å›²ã‚’è¨ˆç®—
                start_idx = batch_idx * BATCH_SIZE
                end_idx = min((batch_idx + 1) * BATCH_SIZE, total_docs)
                batch_documents = all_documents[start_idx:end_idx]
                
                # é€²æ—æ›´æ–°
                progress = (batch_idx + 1) / total_batches
                progress_bar.progress(progress)
                status_text.markdown(f"**é€²æ—: {int(progress * 100)}% ({batch_idx + 1}/{total_batches}ãƒãƒƒãƒ) - ãƒãƒƒãƒ{batch_idx + 1}å‡¦ç†ä¸­...**")
                
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
                batch_start_time = time.time()
                
                if summary_mode == "è‡ªå‹•è¦ç´„":
                    prompt = get_summary_prompt(batch_documents)
                else:
                    prompt = get_custom_batch_prompt(
                        batch_documents, 
                        custom_instruction, 
                        batch_idx + 1, 
                        total_batches
                    )
                
                # è¦ç´„ç”Ÿæˆï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰
                max_retries = 3
                retry_count = 0
                batch_summary = None
                
                while retry_count < max_retries and batch_summary is None:
                    try:
                        batch_summary = generate_summary(client, prompt, model=selected_model)
                    except Exception as e:
                        error_str = str(e)
                        retry_count += 1
                        
                        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯60ç§’å¾…æ©Ÿ
                        if "rate_limit" in error_str.lower() or "429" in error_str:
                            if retry_count < max_retries:
                                st.warning(f"âš ï¸ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã€‚60ç§’å¾…æ©Ÿå¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™... ({retry_count}/{max_retries})")
                                time.sleep(60)
                            else:
                                st.error(f"âŒ ãƒãƒƒãƒ{batch_idx + 1}ã§ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ãŒç¶™ç¶šã—ã¦ã„ã¾ã™ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                        # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼
                        else:
                            if retry_count < max_retries:
                                st.warning(f"âš ï¸ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã€‚30ç§’å¾…æ©Ÿå¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™... ({retry_count}/{max_retries})")
                                time.sleep(30)
                            else:
                                st.error(f"âŒ ãƒãƒƒãƒ{batch_idx + 1}ã§ã‚¨ãƒ©ãƒ¼ãŒç¶™ç¶šã—ã¦ã„ã¾ã™: {error_str}")
                
                batch_end_time = time.time()
                processing_time = batch_end_time - batch_start_time
                processing_times.append(processing_time)
                
                if batch_summary:
                    batch_results.append(batch_summary)
                else:
                    st.error(f"âŒ ãƒãƒƒãƒ{batch_idx + 1}ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            
            # å…¨ãƒãƒƒãƒå®Œäº† - é€²æ—è¡¨ç¤ºã‚’æ¶ˆå»
            progress_placeholder.empty()
            
            # å‡¦ç†å®Œäº†ã®é€šçŸ¥ï¼ˆä¸€æ™‚çš„ã«è¡¨ç¤ºï¼‰
            temp_status = st.empty()
            temp_status.success(f"âœ… å…¨{len(batch_results)}ãƒãƒƒãƒå®Œäº†")
            time.sleep(1)
            temp_status.empty()
            
            # ===== æœ€çµ‚çµ±åˆå‡¦ç† =====
            if batch_results and not st.session_state.get("stop_processing", False):
                # çµ±åˆå‡¦ç†ã®é€²æ—è¡¨ç¤ºç”¨ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
                integration_placeholder = st.empty()
                
                with integration_placeholder.container():
                    st.markdown("### ğŸ”„ æœ€çµ‚çµ±åˆåˆ†æã‚’å®Ÿè¡Œä¸­...")
                    st.info(f"""
                    {len(batch_results)}å€‹ã®ãƒãƒƒãƒçµæœã‚’çµ±åˆã—ã¦ã€
                    å…¨ä½“è¦–ç‚¹ã§ã®åˆ†æã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...
                    
                    â³ æ¨å®šæ®‹ã‚Šæ™‚é–“: ç´„30-60ç§’
                    """)
                
                try:
                    integration_start_time = time.time()
                    
                    # çµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
                    if summary_mode == "è‡ªå‹•è¦ç´„":
                        integration_prompt = f"""
ä»¥ä¸‹ã¯ã€å…¨{total_docs}ä»¶ã®è‡ªæ²»ä½“æ–‡æ›¸ã‚’{len(batch_results)}ãƒãƒƒãƒã«åˆ†ã‘ã¦è¦ç´„ã—ãŸçµæœã§ã™ã€‚
å„ãƒãƒƒãƒã§ã¯è‡ªæ²»ä½“ã”ã¨ã«åˆ†æãŒã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚

{chr(10).join([f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”{chr(10)}ãƒãƒƒãƒ{i+1}ã®è¦ç´„{chr(10)}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”{chr(10)}{result}{chr(10)}" for i, result in enumerate(batch_results)])}

# çµ±åˆè¦ç´„ã®æŒ‡ç¤º
ä¸Šè¨˜ã®å„ãƒãƒƒãƒè¦ç´„ã‚’çµ±åˆã—ã€å…¨ä½“ã‚’ä¿¯ç°ã—ãŸç·åˆçš„ãªè¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

# çµ±åˆæ™‚ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆ
1. **è‡ªæ²»ä½“ã”ã¨ã®æƒ…å ±ã‚’çµ±åˆ**: åŒã˜è‡ªæ²»ä½“ãŒè¤‡æ•°ãƒãƒƒãƒã«ç™»å ´ã™ã‚‹å ´åˆã¯æƒ…å ±ã‚’çµ±åˆã—ã¦ãã ã•ã„
2. **å…·ä½“æ€§ã‚’ä¿æŒ**: æ ¹æ‹ ã¨ãªã‚‹è¨˜è¼‰ã‚„å…·ä½“çš„ãªæ–½ç­–åã‚’ä¿æŒã—ã¦ãã ã•ã„
3. **é‡è¤‡ã‚’æ’é™¤**: åŒã˜å†…å®¹ãŒè¤‡æ•°å›å‡ºç¾ã™ã‚‹å ´åˆã¯1å›ã«ã¾ã¨ã‚ã¦ãã ã•ã„

# å‡ºåŠ›å½¢å¼
ä»¥ä¸‹ã®æ§‹æˆã§å‡ºåŠ›ã—ã¦ãã ã•ã„:

ã€å…¨ä½“ã‚µãƒãƒªãƒ¼ã€‘ï¼ˆ200-300æ–‡å­—ï¼‰
æ¤œç´¢çµæœå…¨ä½“ã®å‚¾å‘ã‚’ä¿¯ç°

ã€è‡ªæ²»ä½“åˆ¥ã®çµ±åˆåˆ†æã€‘
å„è‡ªæ²»ä½“ã®ç‰¹å¾´ã‚’ã€æ ¹æ‹ ã¨ãªã‚‹è¨˜è¼‰ã¨ã¨ã‚‚ã«æ•´ç†

â–  éƒ½é“åºœçœŒå å¸‚åŒºç”ºæ‘å
- ç‰¹å¾´: ...
- æ ¹æ‹ ã¨ãªã‚‹è¨˜è¼‰: ã€Œã€‡ã€‡ã€‡ã€
- å¹´åº¦: ...

**é‡è¦: ã“ã®ãƒãƒƒãƒã«å«ã¾ã‚Œã‚‹ã™ã¹ã¦ã®è‡ªæ²»ä½“ã«ã¤ã„ã¦è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚çœç•¥ã‚„ã€Œä»¥ä¸‹çœç•¥ã€ã¯ä¸å¯ã€‚**

ã€ä¸»è¦ãƒ†ãƒ¼ãƒã€‘
æœ€ã‚‚é »å‡ºã™ã‚‹ãƒ†ãƒ¼ãƒã‚’3-5å€‹

ã€åœ°åŸŸåˆ¥ã®å‚¾å‘ã€‘
åœ°åŸŸã”ã¨ã®ç‰¹å¾´ãŒã‚ã‚Œã°è¨˜è¼‰

ã€æ™‚ç³»åˆ—ã®å¤‰åŒ–ã€‘
å¹´åº¦ã«ã‚ˆã‚‹å¤‰åŒ–ã‚„æ¨ç§»ãŒã‚ã‚Œã°è¨˜è¼‰

ã€é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ TOP5-10ã€‘
é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
"""
                    else:
                        integration_prompt = get_custom_integration_prompt(
                            batch_results, 
                            custom_instruction, 
                            total_docs
                        )
                    
                    final_summary = generate_summary(client, integration_prompt, model=selected_model)
                    
                    integration_end_time = time.time()
                    integration_time = integration_end_time - integration_start_time
                    
                    if final_summary:
                        # çµ±åˆå‡¦ç†ã®é€²æ—è¡¨ç¤ºã‚’æ¶ˆå»
                        integration_placeholder.empty()
                        
                        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆä¿å­˜å‰ã«ä½œæˆï¼‰
                        download_content = f"""# {'ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ' if summary_mode == 'ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ' else 'è‡ªå‹•è¦ç´„'}çµæœï¼ˆå®Œå…¨ç‰ˆï¼‰

## åŸºæœ¬æƒ…å ±
- å®Ÿè¡Œæ—¥æ™‚: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- å¯¾è±¡æ–‡æ›¸æ•°: {total_docs}ä»¶
- ãƒãƒƒãƒæ•°: {len(batch_results)}
- å‡¦ç†æ™‚é–“: {(sum(processing_times) + integration_time) // 60:.0f}åˆ†{(sum(processing_times) + integration_time) % 60:.0f}ç§’

## æœ€çµ‚çµ±åˆçµæœ

{final_summary}

---

## å„ãƒãƒƒãƒã®è©³ç´°çµæœ

"""
                        for i, result in enumerate(batch_results, 1):
                            start_idx = (i - 1) * BATCH_SIZE + 1
                            end_idx = min(i * BATCH_SIZE, total_docs)
                            download_content += f"""### ãƒãƒƒãƒ{i}ï¼ˆæ–‡æ›¸{start_idx}-{end_idx}ä»¶ï¼‰

{result}

---

"""
                        
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«çµæœã‚’ä¿å­˜
                        st.session_state['summary_result'] = final_summary
                        st.session_state['summary_download_content'] = download_content
                        st.session_state['summary_total_docs'] = total_docs
                        st.session_state['summary_batch_count'] = len(batch_results)
                        st.session_state['summary_processing_time'] = sum(processing_times) + integration_time
                        st.session_state['summary_mode'] = summary_mode
                        
                        # æœ€çµ‚çµæœã®è¡¨ç¤º
                        with result_placeholder.container():
                            st.markdown("# ğŸ¯ æœ€çµ‚çµ±åˆçµæœ")
                            st.markdown(final_summary)
                            
                            # å®Œäº†æƒ…å ±ã¨å‡¦ç†æ™‚é–“
                            total_processing_time = sum(processing_times) + integration_time
                            st.success(f"""
                            âœ… {'ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ' if summary_mode == 'ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ' else 'è‡ªå‹•è¦ç´„'}ãŒå®Œäº†ã—ã¾ã—ãŸ
                            
                            - å‡¦ç†æ¸ˆã¿: {total_docs}ä»¶ï¼ˆ{len(batch_results)}ãƒãƒƒãƒ + çµ±åˆ1å›ï¼‰
                            - å‡¦ç†æ™‚é–“: {total_processing_time // 60:.0f}åˆ†{total_processing_time % 60:.0f}ç§’
                            """)
                        
                        # ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰çµæœã‚’å†è¡¨ç¤º
                        st.rerun()
                    
                except Exception as e:
                    integration_placeholder.empty()
                    
                    # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ
                    error_download_content = f"""# ãƒãƒƒãƒå‡¦ç†çµæœï¼ˆçµ±åˆå¤±æ•—ï¼‰

## åŸºæœ¬æƒ…å ±
- å®Ÿè¡Œæ—¥æ™‚: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- å¯¾è±¡æ–‡æ›¸æ•°: {total_docs}ä»¶
- ãƒãƒƒãƒæ•°: {len(batch_results)}
- å‡¦ç†æ™‚é–“: {sum(processing_times) // 60:.0f}åˆ†{sum(processing_times) % 60:.0f}ç§’

## ã‚¨ãƒ©ãƒ¼æƒ…å ±
{str(e)}

## å„ãƒãƒƒãƒã®çµæœ

"""
                    for i, result in enumerate(batch_results, 1):
                        start_idx = (i - 1) * BATCH_SIZE + 1
                        end_idx = min(i * BATCH_SIZE, total_docs)
                        error_download_content += f"""### ãƒãƒƒãƒ{i}ï¼ˆæ–‡æ›¸{start_idx}-{end_idx}ä»¶ï¼‰

{result}

---

"""
                    
                    with result_placeholder.container():
                        st.error(f"âš ï¸ æœ€çµ‚çµ±åˆå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                        
                        st.warning("""
                        å„ãƒãƒƒãƒã®åˆ†æçµæœã¯æ­£å¸¸ã«å–å¾—ã§ãã¦ã„ã¾ã™ã€‚
                        ä»¥ä¸‹ã®å¯¾å‡¦æ³•ã‚’ãŠè©¦ã—ãã ã•ã„:
                        
                        1. å„ãƒãƒƒãƒçµæœã‚’ç¢ºèªã™ã‚‹ï¼ˆçµ±åˆãªã—ã§ã‚‚æœ‰ç”¨ãªæƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼‰
                        2. ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚ˆã‚Šç°¡æ½”ã«ã—ã¦å†å®Ÿè¡Œ
                        3. å¯¾è±¡æ–‡æ›¸æ•°ã‚’æ¸›ã‚‰ã—ã¦å†å®Ÿè¡Œ
                        """)
                        
                        # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã‚’æä¾›
                        st.download_button(
                            label="ğŸ“¥ ãƒãƒƒãƒçµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=error_download_content,
                            file_name=f"summary_batches_error_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                            mime="text/plain",
                            key=f"download_error_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
                        )
            
            elif not batch_results:
                progress_placeholder.empty()
                with result_placeholder.container():
                    st.error("âŒ ã™ã¹ã¦ã®ãƒãƒƒãƒå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            
        except Exception as e:
            if 'progress_placeholder' in locals():
                progress_placeholder.empty()
            if 'result_placeholder' in locals():
                with result_placeholder.container():
                    st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            else:
                st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        
        finally:
            # ä¸­æ–­ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
            st.session_state.stop_processing = False
    
    # ===== ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰çµæœã‚’å¾©å…ƒã—ã¦è¡¨ç¤º =====
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸå¾Œã‚‚ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§çµæœãŒå†è¡¨ç¤ºã•ã‚Œã‚‹
    if 'summary_result' in st.session_state and 'summary_mode' in st.session_state:
        st.markdown("---")
        st.markdown("# ğŸ¯ æœ€çµ‚çµ±åˆçµæœ")
        st.markdown(st.session_state['summary_result'])
        
        # å®Œäº†æƒ…å ±
        st.success(f"""
        âœ… {st.session_state.get('summary_mode', 'è¦ç´„')}ãŒå®Œäº†ã—ã¾ã—ãŸ
        
        - å‡¦ç†æ¸ˆã¿: {st.session_state.get('summary_total_docs', 0)}ä»¶ï¼ˆ{st.session_state.get('summary_batch_count', 0)}ãƒãƒƒãƒ + çµ±åˆ1å›ï¼‰
        - å‡¦ç†æ™‚é–“: {st.session_state.get('summary_processing_time', 0) // 60:.0f}åˆ†{st.session_state.get('summary_processing_time', 0) % 60:.0f}ç§’
        """)
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        col1, col2, col3 = st.columns([2, 2, 4])
        with col1:
            st.download_button(
                label="ğŸ“¥ å®Œå…¨ç‰ˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=st.session_state.get('summary_download_content', ''),
                file_name=f"summary_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                mime="text/plain",
                key="download_full_persistent"
            )
        with col2:
            st.download_button(
                label="ğŸ“Š çµ±åˆçµæœã®ã¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=st.session_state.get('summary_result', ''),
                file_name=f"summary_final_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                mime="text/plain",
                key="download_final_persistent"
            )
    
    # ä½¿ç”¨ä¸Šã®æ³¨æ„
    with st.expander("â„¹ï¸ AIè¦ç´„ã®ä½¿ç”¨ä¸Šã®æ³¨æ„"):
        st.markdown(f"""
        - AIã«ã‚ˆã‚‹è¦ç´„ã¯å‚è€ƒæƒ…å ±ã§ã™ã€‚é‡è¦ãªæ±ºå®šã«ã¯å¿…ãšåŸæ–‡ã‚’ç¢ºèªã—ã¦ãã ã•ã„
        - **æ–‡æ›¸æ•°åˆ¶é™**: åˆ†æå¯¾è±¡ã¯ä¸Šé™{MAX_DOCS_FOR_SUMMARY}ä»¶ã¾ã§ã§ã™
        - **ãƒãƒƒãƒå‡¦ç†**: {BATCH_SIZE}ä»¶ãšã¤å‡¦ç†ã—ã€æœ€å¾Œã«çµ±åˆã—ã¾ã™
        - **ãƒ‡ãƒ¼ã‚¿ä¸¦ã³æ›¿ãˆ**: åˆ†æå‰ã«å›£ä½“ã‚³ãƒ¼ãƒ‰ãƒ»å¹´åº¦ãƒ»ãƒ•ã‚¡ã‚¤ãƒ«IDã§ä¸¦ã³æ›¿ãˆã‚’è¡Œã„ã¾ã™
        - æœ¬æ–‡ã¯æœ€å¤§{MAX_CHARS_PER_DOC}æ–‡å­—ã¾ã§ä½¿ç”¨ã•ã‚Œã¾ã™
        - å‡¦ç†ä¸­ã«ä¸­æ–­ãƒœã‚¿ãƒ³ã§åœæ­¢ã§ãã¾ã™
        - ã‚¨ãƒ©ãƒ¼æ™‚ã¯è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ã‚’è¡Œã„ã¾ã™ï¼ˆæœ€å¤§3å›ï¼‰
        - **ãƒˆãƒ¼ã‚¯ãƒ³æœ€é©åŒ–**: ä¸è¦ãªåˆ—ã‚’é€ä¿¡ã‹ã‚‰é™¤å¤–ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å‰Šæ¸›ã—ã¦ã„ã¾ã™
        - **è¡¨ç¤º**: çµ±åˆçµæœã®ã¿è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚å„ãƒãƒƒãƒã®è©³ç´°ã¯å®Œå…¨ç‰ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ç¢ºèªã§ãã¾ã™
        - **ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¾Œã‚‚çµæœè¡¨ç¤º**: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã‚‚çµæœã¯æ¶ˆãˆã¾ã›ã‚“
        """)