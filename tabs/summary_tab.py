"""
AIè¦ç´„ã‚¿ãƒ–ã®è¡¨ç¤ºå‡¦ç†ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°æœ€é©åŒ–ç‰ˆï¼‰
"""

import datetime
import streamlit as st
import pandas as pd
from elasticsearch import Elasticsearch
from config import get_secret
from data_fetcher import fetch_search_results
from openai_helper import get_openai_client, generate_summary
from prompt import get_summary_prompt, get_custom_prompt


def render_summary_tab(
    es: Elasticsearch,
    query: dict,
    jichitai: pd.DataFrame,
    catmap: pd.DataFrame,
    result_limit: int
):
    """
    AIè¦ç´„ã‚¿ãƒ–ã®è¡¨ç¤º
    
    Args:
        es: Elasticsearchã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        query: æ¤œç´¢ã‚¯ã‚¨ãƒª
        jichitai: è‡ªæ²»ä½“ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿
        catmap: ã‚«ãƒ†ã‚´ãƒªãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿
        result_limit: è¡¨ç¤ºä»¶æ•°ä¸Šé™
    """
    st.subheader("ğŸ¤– GPT ã«ã‚ˆã‚‹è¦ç´„")
    
    # APIã‚­ãƒ¼ã®ç¢ºèª
    openai_api_key = get_secret("OPENAI_API_KEY")
    if not openai_api_key:
        st.error("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Streamlit Secretsã« `OPENAI_API_KEY` ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
        return
    
    # æ¤œç´¢çµæœã®ç¢ºèª
    if not query:
        st.warning("ã¾ãšæ¤œç´¢æ¡ä»¶ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return
    
    df_results = fetch_search_results(es, query, jichitai, catmap, result_limit)
    
    if df_results.empty:
        st.warning("è¦ç´„ã™ã‚‹æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ¤œç´¢æ¡ä»¶ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return
    
    # ===== ğŸ”§ æ–‡æ›¸æ•°åˆ¶é™ï¼ˆæ–¹ç­–2-Bï¼‰ =====
    MAX_DOCS_FOR_SUMMARY = 1000  # æœ€å¤§100ä»¶ã¾ã§
    
    total_docs = len(df_results)
    if total_docs > MAX_DOCS_FOR_SUMMARY:
        st.warning(f"âš ï¸ æ¤œç´¢çµæœãŒ{total_docs}ä»¶ã‚ã‚Šã¾ã™ã€‚ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã®ãŸã‚ã€ä¸Šä½{MAX_DOCS_FOR_SUMMARY}ä»¶ã®ã¿ã‚’è¦ç´„ã—ã¾ã™ã€‚")
        df_results = df_results.head(MAX_DOCS_FOR_SUMMARY)
    
    st.info(f"ğŸ“Š è¦ç´„å¯¾è±¡: {len(df_results)}ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    model_options = {
        # "GPT-4o": "gpt-4o",
        "GPT-4o mini": "gpt-4o-mini",
        # "GPT-4 Turbo": "gpt-4-turbo-preview",
        # "GPT-3.5 Turbo": "gpt-3.5-turbo"
    }
    
    selected_model_name = st.selectbox(
        "ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«",
        options=list(model_options.keys()),
        index=0,
        help="GPT-4o miniã§æ¤œè¨¼ä¸­ã§ã™ã€‚"
    )
    selected_model = model_options[selected_model_name]
    
    # è¦ç´„ãƒ¢ãƒ¼ãƒ‰é¸æŠ
    summary_mode = st.radio(
        "è¦ç´„ãƒ¢ãƒ¼ãƒ‰",
        ["è‡ªå‹•è¦ç´„", "ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"],
        horizontal=True
    )
    
    # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å…¥åŠ›
    custom_instruction = ""
    if summary_mode == "ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ":
        custom_instruction = st.text_area(
            "AIã¸ã®æŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            placeholder="ä¾‹: ã“ã‚Œã‚‰ã®æ–‡æ›¸ã‹ã‚‰ç’°å¢ƒæ”¿ç­–ã«é–¢ã™ã‚‹å…±é€šã®èª²é¡Œã‚’3ã¤æŠ½å‡ºã—ã¦ãã ã•ã„",
            height=100
        )
    
    # è¦ç´„å®Ÿè¡Œãƒœã‚¿ãƒ³
    if st.button("ğŸš€ è¦ç´„ã‚’å®Ÿè¡Œ", type="primary"):
        with st.spinner("AIãŒè¦ç´„ã‚’ç”Ÿæˆä¸­..."):
            try:
                # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
                client = get_openai_client(openai_api_key)
                
                # ===== ğŸ”§ ãƒˆãƒ¼ã‚¯ãƒ³æ•°å‰Šæ¸›: å¿…è¦ãªåˆ—ã ã‘ã‚’æŠ½å‡º =====
                essential_columns = [
                    'éƒ½é“åºœçœŒ', 
                    'å¸‚åŒºç”ºæ‘', 
                    'è³‡æ–™ã‚«ãƒ†ã‚´ãƒª', 
                    'è³‡æ–™å', 
                    'æœ¬æ–‡', 
                    'é–‹å§‹å¹´åº¦', 
                    'çµ‚äº†å¹´åº¦'
                ]
                
                # å­˜åœ¨ã™ã‚‹åˆ—ã ã‘ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                available_columns = [col for col in essential_columns if col in df_results.columns]
                
                # å¿…è¦ãªåˆ—ã ã‘ã‚’æŠ½å‡ºã—ã¦DataFrameã‚’ä½œæˆ
                df_essential = df_results[available_columns].copy()
                
                # DataFrameã‚’è¾æ›¸ã®ãƒªã‚¹ãƒˆã«å¤‰æ›
                documents = df_essential.to_dict('records')
                
                # ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›æƒ…å ±ã‚’è¡¨ç¤º
                # original_size = len(df_results.columns)
                # optimized_size = len(available_columns)
                # st.info(f"ğŸ”§ ãƒˆãƒ¼ã‚¯ãƒ³æœ€é©åŒ–: {original_size}åˆ— â†’ {optimized_size}åˆ—ã«å‰Šæ¸›")
                
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
                if summary_mode == "è‡ªå‹•è¦ç´„":
                    prompt = get_summary_prompt(documents)
                else:
                    if not custom_instruction:
                        st.error("ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                        st.stop()
                    prompt = get_custom_prompt(documents, custom_instruction)
                
                # è¦ç´„ç”Ÿæˆ
                summary = generate_summary(client, prompt, model=selected_model)
                
                if summary:
                    st.success("âœ… è¦ç´„ãŒå®Œæˆã—ã¾ã—ãŸ")
                    
                    # è¦ç´„çµæœã®è¡¨ç¤º
                    st.markdown("### ğŸ“ è¦ç´„çµæœ")
                    st.markdown(summary)
                    
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                    st.download_button(
                        label="ğŸ“¥ è¦ç´„ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=summary,
                        file_name=f"summary_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain"
                    )
                else:
                    st.error("è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    # ä½¿ç”¨ä¸Šã®æ³¨æ„
    with st.expander("â„¹ï¸ AIè¦ç´„ã®ä½¿ç”¨ä¸Šã®æ³¨æ„"):
        st.markdown("""
        - AIã«ã‚ˆã‚‹è¦ç´„ã¯å‚è€ƒæƒ…å ±ã§ã™ã€‚é‡è¦ãªæ±ºå®šã«ã¯å¿…ãšåŸæ–‡ã‚’ç¢ºèªã—ã¦ãã ã•ã„
        - **æ–‡æ›¸æ•°åˆ¶é™**: æ¤œç´¢çµæœãŒ100ä»¶ã‚’è¶…ãˆã‚‹å ´åˆã€ä¸Šä½100ä»¶ã®ã¿ã‚’è¦ç´„ã—ã¾ã™
        - æœ¬æ–‡ã¯æœ€å¤§2000æ–‡å­—ã¾ã§ä½¿ç”¨ã•ã‚Œã¾ã™
        - OpenAI APIã®åˆ©ç”¨åˆ¶é™ã«å¿œã˜ã¦ã€ä¸€åº¦ã«å‡¦ç†ã§ãã‚‹ä»¶æ•°ã«åˆ¶é™ãŒã‚ã‚Šã¾ã™
        - ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ã‚³ã‚¹ãƒˆãŒç•°ãªã‚Šã¾ã™ï¼š
          - **GPT-4o**: æœ€æ–°ã§é«˜æ€§èƒ½ï¼ˆã‚„ã‚„é«˜ã‚³ã‚¹ãƒˆï¼‰
          - **GPT-4o mini**: GPT-4oã®è»½é‡ç‰ˆï¼ˆãƒãƒ©ãƒ³ã‚¹å‹ï¼‰
          - **GPT-4 Turbo**: é«˜æ€§èƒ½ï¼ˆé«˜ã‚³ã‚¹ãƒˆï¼‰
          - **GPT-3.5 Turbo**: é«˜é€Ÿã§ä½ã‚³ã‚¹ãƒˆ
        - **ãƒˆãƒ¼ã‚¯ãƒ³æœ€é©åŒ–**: ä¸è¦ãªåˆ—ï¼ˆURLã€ãƒ•ã‚¡ã‚¤ãƒ«IDãªã©ï¼‰ã‚’é€ä¿¡ã‹ã‚‰é™¤å¤–ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å‰Šæ¸›ã—ã¦ã„ã¾ã™
        """)